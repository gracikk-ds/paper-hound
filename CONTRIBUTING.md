# Contributing to ArXivPaperHound

Thank you for your interest in contributing to ArXivPaperHound! This guide will help you get started with development.

## Table of Contents

- [Development Setup](#development-setup)
- [Project Structure](#project-structure)
- [Development Workflow](#development-workflow)
- [Testing](#testing)
- [Code Quality](#code-quality)
- [Just Commands Reference](#just-commands-reference)
- [Pull Request Process](#pull-request-process)

## Development Setup

### Prerequisites

- Python 3.12 or higher
- Git
- Docker and Docker Compose (for Qdrant)
- Google Cloud account with Vertex AI enabled
- Notion integration token
- Telegram bot token
- S3-compatible storage credentials

### Local Development Installation

1. **Clone the Repository**

   ```bash
   git clone https://github.com/yourusername/ArXivPaperHound.git
   cd ArXivPaperHound
   ```

2. **Create Virtual Environment**

   ```bash
   python -m venv .venv
   ```

3. **Activate Virtual Environment**

   On macOS/Linux:

   ```bash
   source .venv/bin/activate
   ```

   On Windows:

   ```cmd
   .venv\Scripts\activate
   ```

4. **Install Dependencies**

   ```bash
   # Production dependencies
   pip install -r requirements.txt

   # Development dependencies (linting, testing, etc.)
   pip install -r requirements-dev.txt
   ```

5. **Install Pre-commit Hooks** (Optional but recommended)

   ```bash
   pre-commit install
   ```

6. **Configure Environment Variables**

   ```bash
   cp template.env .env
   # Edit .env with your credentials
   ```

   See [docs/SETUP.md](docs/SETUP.md) for detailed configuration instructions.

7. **Start Qdrant**

   Using Docker Compose:

   ```bash
   docker-compose up -d qdrant
   ```

   Or standalone Docker:

   ```bash
   docker run -p 6333:6333 \
     -v $(pwd)/storage/qdrant_storage:/qdrant/storage \
     qdrant/qdrant
   ```

8. **Run the Application**

   Using Uvicorn directly:

   ```bash
   uvicorn src.app:create_app --factory --reload --port 8001
   ```

   Or using the Just command:

   ```bash
   just run
   ```

9. **Verify Setup**

   ```bash
   curl http://localhost:8001/health/ping
   # Expected: "ðŸ“ pong!"
   ```

### Development with Telegram Bot

To run the Telegram bot locally:

```bash
python telegram_bot/bot.py
```

The bot will start polling for messages. You can test it by messaging your bot on Telegram.

## Project Structure

```text
ArXivPaperHound/
â”œâ”€â”€ src/                          # Main application source code
â”‚   â”œâ”€â”€ app.py                    # FastAPI application factory
â”‚   â”œâ”€â”€ settings.py               # Configuration management (pydantic-settings)
â”‚   â”‚
â”‚   â”œâ”€â”€ containers/               # Dependency injection
â”‚   â”‚   â””â”€â”€ containers.py         # AppContainer with service singletons
â”‚   â”‚
â”‚   â”œâ”€â”€ routes/                   # API endpoints
â”‚   â”‚   â”œâ”€â”€ routers.py            # Router definitions
â”‚   â”‚   â”œâ”€â”€ health_endpoints.py  # Health check endpoints
â”‚   â”‚   â”œâ”€â”€ processor_endpoints.py  # Paper processing API
â”‚   â”‚   â”œâ”€â”€ workflow_endpoints.py   # Workflow trigger API
â”‚   â”‚   â””â”€â”€ ai_endpoint.py        # AI-related endpoints
â”‚   â”‚
â”‚   â”œâ”€â”€ service/                  # Core business logic
â”‚   â”‚   â”œâ”€â”€ workflow.py           # Main workflow orchestration
â”‚   â”‚   â”œâ”€â”€ processor.py          # Paper processing coordinator
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ai_researcher/        # LLM-based services
â”‚   â”‚   â”‚   â”œâ”€â”€ classifier.py     # Paper relevance classifier
â”‚   â”‚   â”‚   â””â”€â”€ summarizer.py     # PDF summarization with vision
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ vector_db/            # Vector database integration
â”‚   â”‚   â”‚   â”œâ”€â”€ embedder.py       # Gemini embedding service
â”‚   â”‚   â”‚   â”œâ”€â”€ vector_storage.py # Qdrant client wrapper
â”‚   â”‚   â”‚   â””â”€â”€ processing_cache.py  # Caching layer
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ arxiv/                # ArXiv API integration
â”‚   â”‚   â”‚   â”œâ”€â”€ api.py            # ArXiv API client
â”‚   â”‚   â”‚   â””â”€â”€ fetcher.py        # Paper fetching logic
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ notion_db/            # Notion integration
â”‚   â”‚       â”œâ”€â”€ client.py         # Notion API client
â”‚   â”‚       â””â”€â”€ uploader.py       # Paper upload logic
â”‚   â”‚
â”‚   â””â”€â”€ utils/                    # Utilities and schemas
â”‚       â”œâ”€â”€ schemas.py            # Pydantic models for requests/responses
â”‚       â”œâ”€â”€ logging_config.py     # Logging configuration
â”‚       â””â”€â”€ helpers.py            # Helper functions
â”‚
â”œâ”€â”€ telegram_bot/                 # Telegram bot application
â”‚   â”œâ”€â”€ bot.py                    # Bot initialization and entry point
â”‚   â”œâ”€â”€ handlers/                 # Command and callback handlers
â”‚   â”‚   â”œâ”€â”€ search_handlers.py   # Search and discovery commands
â”‚   â”‚   â”œâ”€â”€ paper_handlers.py    # Paper management commands
â”‚   â”‚   â”œâ”€â”€ subscription_handlers.py  # Subscription commands
â”‚   â”‚   â””â”€â”€ admin_handlers.py    # Admin-only commands
â”‚   â”œâ”€â”€ subscriptions.py          # Subscription management logic
â”‚   â””â”€â”€ notifications.py          # Notification system
â”‚
â”œâ”€â”€ tests/                        # Test suite
â”‚   â”œâ”€â”€ conftest.py               # Pytest fixtures and configuration
â”‚   â”œâ”€â”€ test_workflow_endpoints.py   # Workflow API tests
â”‚   â”œâ”€â”€ test_processor_endpoints.py  # Processor API tests
â”‚   â”œâ”€â”€ test_classifier.py        # Classifier unit tests
â”‚   â”œâ”€â”€ test_summarizer.py        # Summarizer unit tests
â”‚   â””â”€â”€ test_embeddings.py        # Embedding service tests
â”‚
â”œâ”€â”€ prompts/                      # LLM prompt templates
â”‚   â”œâ”€â”€ classifier/               # Classification prompts by category
â”‚   â”‚   â”œâ”€â”€ default.txt
â”‚   â”‚   â”œâ”€â”€ machine_learning.txt
â”‚   â”‚   â””â”€â”€ quantum_computing.txt
â”‚   â””â”€â”€ summarizer/
â”‚       â””â”€â”€ summarize.txt
â”‚
â”œâ”€â”€ storage/                      # Local storage directories
â”‚   â”œâ”€â”€ qdrant_storage/           # Qdrant data persistence
â”‚   â”œâ”€â”€ pdfs/                     # Downloaded PDFs cache
â”‚   â””â”€â”€ images/                   # Extracted images cache
â”‚
â”œâ”€â”€ credentials/                  # Service account credentials (gitignored)
â”‚   â””â”€â”€ gen_lang_client.json      # Google Cloud service account
â”‚
â”œâ”€â”€ docs/                         # Documentation
â”‚   â”œâ”€â”€ SETUP.md                  # External services setup guide
â”‚   â””â”€â”€ API.md                    # REST API reference
â”‚
â”œâ”€â”€ docker-compose.yml            # Docker services configuration
â”œâ”€â”€ Dockerfile                    # Application container image
â”œâ”€â”€ justfile                      # Just command recipes
â”œâ”€â”€ pyproject.toml                # Project metadata and tool configuration
â”œâ”€â”€ requirements.txt              # Production dependencies
â”œâ”€â”€ requirements-dev.txt          # Development dependencies
â”œâ”€â”€ template.env                  # Environment variable template
â”œâ”€â”€ .env                          # Local environment config (gitignored)
â”œâ”€â”€ .gitignore                    # Git ignore rules
â”œâ”€â”€ .pre-commit-config.yaml       # Pre-commit hooks configuration
â”œâ”€â”€ README.md                     # Project overview and quick start
â”œâ”€â”€ CONTRIBUTING.md               # This file
â”œâ”€â”€ LICENSE                       # MIT license
â””â”€â”€ CLAUDE.md                     # Project instructions for Claude Code
```

## Development Workflow

### Making Changes

1. **Create a Feature Branch**

   ```bash
   git checkout -b feature/your-feature-name
   ```

2. **Make Your Changes**

   - Write code following the existing style
   - Add tests for new functionality
   - Update documentation if needed

3. **Run Tests and Linting**

   ```bash
   just lint    # Format and lint code
   just test    # Run test suite
   ```

4. **Commit Your Changes**

   ```bash
   git add .
   git commit -m "Add feature: your feature description"
   ```

   Follow conventional commit format:
   - `feat:` for new features
   - `fix:` for bug fixes
   - `docs:` for documentation changes
   - `test:` for test additions/changes
   - `refactor:` for code refactoring
   - `chore:` for maintenance tasks

5. **Push and Create Pull Request**

   ```bash
   git push origin feature/your-feature-name
   ```

   Then create a pull request on GitHub.

### Adding New Features

When adding significant features:

1. **Update Tests**: Add comprehensive test coverage
2. **Update Documentation**:
   - Update README.md if user-facing
   - Update API.md for new endpoints
   - Update SETUP.md for new configuration
3. **Update CLAUDE.md**: Document architecture changes for AI assistance
4. **Update Type Hints**: Maintain full type coverage

## Testing

### Test-Driven Development

We prefer Test-Driven Development (TDD):

1. Write failing tests first
2. Implement minimal code to pass tests
3. Refactor while keeping tests green

### Running Tests

```bash
# Run all tests
just test

# Run specific test file
just test tests/test_workflow_endpoints.py

# Run tests matching a pattern
pytest -k "test_search"

# Run with verbose output
pytest -v

# Run with coverage report
just coverage
```

### Test Coverage

We aim for >80% test coverage. Check coverage with:

```bash
just coverage
```

This generates an HTML report at `htmlcov/index.html`.

### Writing Tests

Example test structure:

```python
import pytest
from src.service.processor import PapersProcessor


def test_search_papers_returns_results(processor: PapersProcessor):
    """Test that search returns relevant papers."""
    # Arrange
    query = "machine learning"

    # Act
    results = processor.search_papers(query, top_k=5, threshold=0.65)

    # Assert
    assert len(results) > 0
    assert all(r.score >= 0.65 for r in results)


@pytest.mark.parametrize("query,expected_count", [
    ("deep learning", 10),
    ("quantum computing", 5),
])
def test_search_with_different_queries(processor, query, expected_count):
    """Test search with various queries."""
    results = processor.search_papers(query, top_k=expected_count)
    assert len(results) <= expected_count
```

## Code Quality

### Linting and Formatting

We use Ruff for both linting and formatting:

```bash
# Format and lint
just lint

# Check without modifying
ruff check .
ruff format --check .
```

### Pre-commit Hooks

Pre-commit hooks automatically run linting before commits:

```bash
# Install hooks
pre-commit install

# Run manually on all files
pre-commit run --all-files
```

### Type Checking

We use Python type hints throughout the codebase. While we don't currently run mypy in CI, please:

- Add type hints to all function signatures
- Use proper generic types (list[str], dict[str, int], etc.)
- Import types from `typing` when needed

### Code Style Guidelines

- **Line length**: Max 120 characters
- **Imports**: Organized by standard library, third-party, local
- **Docstrings**: Google style for all public functions/classes
- **Naming**:
  - Classes: PascalCase
  - Functions/variables: snake_case
  - Constants: UPPER_SNAKE_CASE
  - Private members: _leading_underscore

Example:

```python
from datetime import date

from pydantic import BaseModel

from src.utils.schemas import Paper


class PaperProcessor:
    """Process and analyze arXiv papers.

    Attributes:
        vector_store: Vector database client for embeddings.
    """

    def __init__(self, vector_store: VectorStore) -> None:
        """Initialize the processor.

        Args:
            vector_store: Vector database client instance.
        """
        self.vector_store = vector_store

    def search_papers(
        self,
        query: str,
        top_k: int = 10,
        threshold: float = 0.65,
    ) -> list[Paper]:
        """Search for papers using semantic similarity.

        Args:
            query: Natural language search query.
            top_k: Maximum number of results to return.
            threshold: Minimum similarity score (0-1).

        Returns:
            List of Paper objects ordered by relevance score.

        Raises:
            ValueError: If threshold is not between 0 and 1.
        """
        if not 0 <= threshold <= 1:
            raise ValueError("Threshold must be between 0 and 1")

        # Implementation here
        return []
```

## Just Commands Reference

We use [Just](https://github.com/casey/just) as a command runner. Here are all available commands:

### Development Commands

```bash
# Show all available commands
just list

# Run the application with auto-reload
just run

# Run the Telegram bot
just bot
```

### Testing Commands

```bash
# Run all tests
just test

# Run specific test file
just test tests/test_workflow_endpoints.py

# Generate HTML coverage report
just coverage
```

### Code Quality Commands

```bash
# Format code and run linter
just lint

# Check formatting without modifying
just check

# Run pre-commit hooks on all files
just pre-commit
```

### Build Commands

```bash
# Build Python package
just build

# Clean build artifacts
just clean

# Print current version
just version
```

### Release Commands

```bash
# Tag current version and push to GitHub
just tag

# Build and publish to PyPI (if configured)
just publish
```

### Docker Commands

```bash
# Build Docker image
just docker-build

# Run with Docker Compose
just docker-up

# Stop Docker services
just docker-down

# View logs
just docker-logs
```

## Pull Request Process

1. **Ensure Tests Pass**

   All tests must pass and coverage should not decrease.

2. **Update Documentation**

   Update relevant documentation for your changes.

3. **Follow Code Style**

   Run `just lint` before committing.

4. **Write Clear Commit Messages**

   Use conventional commits format with clear descriptions.

5. **Describe Your Changes**

   In the PR description, explain:
   - What problem does this solve?
   - How did you solve it?
   - Are there any breaking changes?
   - How can reviewers test this?

6. **Request Review**

   Tag relevant maintainers for review.

7. **Address Feedback**

   Respond to review comments and make requested changes.

8. **Squash Commits** (if requested)

   Maintainers may ask you to squash commits before merging.

## Common Development Tasks

### Adding a New LLM Prompt

1. Create prompt file in `prompts/classifier/` or `prompts/summarizer/`
2. Use clear variable placeholders (e.g., `{query}`, `{abstract}`)
3. Test prompt with actual data
4. Update tests to verify prompt loading

### Adding a New API Endpoint

1. Define request/response schemas in `src/utils/schemas.py`
2. Implement endpoint in appropriate router file
3. Add endpoint to router in `src/routes/routers.py`
4. Write tests in `tests/test_*_endpoints.py`
5. Update `docs/API.md` with endpoint documentation

### Adding a New Telegram Command

1. Create handler function in `telegram_bot/handlers/`
2. Register handler in `telegram_bot/bot.py`
3. Add command to bot description (via BotFather)
4. Update README with command documentation
5. Write integration tests if applicable

### Modifying the Workflow

1. Update `src/service/workflow.py`
2. Ensure backward compatibility or add migration path
3. Update tests in `tests/test_workflow_endpoints.py`
4. Document changes in commit message

## Getting Help

- **Questions**: Open a GitHub Discussion
- **Bugs**: Open a GitHub Issue with reproduction steps
- **Feature Requests**: Open a GitHub Issue with use case description

## License

By contributing, you agree that your contributions will be licensed under the MIT License.
